{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import duckdb\n",
    "import datetime\n",
    "from prefect import flow, task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "### Prefect Tasks\n",
    "\n",
    "A task is a function that represents a discrete unit of work in a Prefect workflow. Tasks are not required â€” you may define Prefect workflows that consist only of flows, using regular Python statements and functions. Tasks enable you to encapsulate elements of your workflow logic in observable units that can be reused across flows and subflows.\n",
    "\n",
    "https://docs.prefect.io/latest/concepts/tasks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction\n",
    "\n",
    "We will be extracting a list of ticker data supported by `polygon API`, and using the list of tickers to extract historical stock data from `yfinance`.\n",
    "\n",
    "`yfinance` is an open-source Python package that scrapes data from `Yahoo finance`. The data can then be accessed in a threaded and Pythonic way.\n",
    "\n",
    "Useful links:\n",
    "*   https://pypi.org/project/yfinance/\n",
    "*   https://polygon.io/docs/stocks/get_v3_reference_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\tasks.py:339: UserWarning: A task named 'extract data' and defined at 'C:\\Users\\Wilberforce Wairagu\\AppData\\Local\\Temp\\ipykernel_5844\\815801278.py:1' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@task(name=\"extract data\", log_prints=True, retries=1)\n",
    "def extract_all_tickers():\n",
    "  BASE_URL = \"https://api.polygon.io/v3/reference/tickers?\"\n",
    "  params = {\"apiKey\" : \"cmDK3EffgqLXrbZ0ZivQ9I7ZAwjHImiX\"}\n",
    "\n",
    "  print(f\"Beginning data extraction from {BASE_URL}\")\n",
    "  try:\n",
    "    res = requests.get(BASE_URL, params=params)\n",
    "    data = res.json()[\"results\"]\n",
    "    df = pd.DataFrame(data)\n",
    "  except Exception as e:\n",
    "    print(f\"Error {e} while ingesting data from {BASE_URL}\")\n",
    "    df = pd.DataFrame()   # return empty dataframe if exception is raised\n",
    "\n",
    "  return df\n",
    "\n",
    "# test_data = extract_all_tickers()\n",
    "# test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\tasks.py:339: UserWarning: A task named 'transform data' and defined at 'C:\\Users\\Wilberforce Wairagu\\AppData\\Local\\Temp\\ipykernel_5844\\2933967443.py:1' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@task(name=\"transform data\",log_prints=True, retries=1)\n",
    "def transform_data(test_data_df : pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Perform transformations and cleaning on a datframe\n",
    "\n",
    "  Parameters:\n",
    "    test_data_df : dataframe containing the raw_extracted data\n",
    "\n",
    "  Returns:\n",
    "    A transformed dataframe\n",
    "\n",
    "  \"\"\"\n",
    "  print(\"Beginning transformations ..........\")\n",
    "\n",
    "  try:\n",
    "    # rename some columns\n",
    "    test_data_df.rename(\n",
    "        columns={'name' : 'company_name', 'locale' : 'country'}, inplace=True\n",
    "        )\n",
    "\n",
    "    # convert the currency columns and country column to uppercase\n",
    "    test_data_df[\"currency_name\"] = test_data_df[\"currency_name\"].str.upper()\n",
    "    test_data_df[\"country\"] = test_data_df[\"country\"].str.upper()\n",
    "    print(\"Currency and country successfully converted to lowercase...\")\n",
    "\n",
    "    # replace the nan values\n",
    "    test_data_df[\"primary_exchange\"] = test_data_df[\"primary_exchange\"].replace(\"nan\", \"Not Listed\")\n",
    "    test_data_df[\"composite_figi\"] = test_data_df[\"composite_figi\"].fillna(\"Not Listed\")\n",
    "    test_data_df[\"share_class_figi\"] = test_data_df[\"share_class_figi\"].fillna(\"Not Listed\")\n",
    "    test_data_df[\"cik\"] = test_data_df[\"cik\"].replace(\"nan\", \"Not Listed\")\n",
    "    print(\"Null values successfully replaced...\")\n",
    "\n",
    "    # change the data types\n",
    "    test_data_df[\"ticker\"] = test_data_df[\"ticker\"].astype(str)\n",
    "    test_data_df[\"company_name\"] = test_data_df[\"company_name\"].astype(str)\n",
    "    test_data_df[\"market\"] = test_data_df[\"market\"].astype(str)\n",
    "    test_data_df[\"country\"] = test_data_df[\"country\"].astype(str)\n",
    "    test_data_df[\"primary_exchange\"] = test_data_df[\"primary_exchange\"].astype(str)\n",
    "    test_data_df[\"cik\"] = test_data_df[\"cik\"].astype(str)\n",
    "    test_data_df[\"composite_figi\"] = test_data_df[\"share_class_figi\"].astype(str)\n",
    "    test_data_df[\"last_updated_utc\"] = pd.to_datetime(test_data_df[\"last_updated_utc\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # create a primary key column\n",
    "    test_data_df[\"company_key\"] = range(1, len(test_data_df) + 1)\n",
    "\n",
    "    cols = [\"company_key\",\"ticker\",\"company_name\",\"market\",\"country\",\"primary_exchange\",\n",
    "            \"cik\",\"composite_figi\",\"last_updated_utc\"]\n",
    "\n",
    "    # Mantain the relative order of the columns\n",
    "    test_data_df = test_data_df[cols]\n",
    "\n",
    "    print(\"Transformation complete...\")\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Exception {e} while transforming data\")\n",
    "    test_data_df = pd.DataFrame()\n",
    "\n",
    "  return test_data_df\n",
    "\n",
    "\n",
    "#transformed_df = transform_data(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\tasks.py:339: UserWarning: A task named 'load data' and defined at 'C:\\Users\\Wilberforce Wairagu\\AppData\\Local\\Temp\\ipykernel_5844\\3356178709.py:1' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@task(name=\"load data\", log_prints=True, retries=3)\n",
    "def load_duckdb(dataframe, db_name, table_name):\n",
    "  \"\"\"Load the cleaned dataframe into a duckdb database\n",
    "\n",
    "  Parameters:\n",
    "    dataframe : input dataframe to be loaded to database\n",
    "    db_name : database to load data in\n",
    "    table_name : table in database where data is loaded\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # connect to duckdb\n",
    "    con = duckdb.connect(db_name)\n",
    "\n",
    "    # write the dataframe to duckdb\n",
    "    dataframe.to_sql(name=table_name, con=con, if_exists=\"replace\", index=\"True\")\n",
    "    print(f\"Data succesfully written to {db_name}\")\n",
    "\n",
    "\n",
    "    # read the data from sql\n",
    "    loaded_df = pd.read_sql(f\"DESCRIBE {table_name}\", con=con)\n",
    "    print(loaded_df)\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Exception {e} while loading data into {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\flows.py:357: UserWarning: A flow named 'Orchestrate pipeline' and defined at 'C:\\Users\\Wilberforce Wairagu\\AppData\\Local\\Temp\\ipykernel_5844\\316093026.py:1' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n",
      "\n",
      " `@flow(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _rust: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m   transformed_df \u001b[38;5;241m=\u001b[39m transform_data(raw_df)\n\u001b[0;32m      5\u001b[0m   load_duckdb(transformed_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinance-DWH.db\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim_companies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\flows.py:1224\u001b[0m, in \u001b[0;36mFlow.__call__\u001b[1;34m(self, return_state, wait_for, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_viz_tracker:\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# this is a subflow, for now return a single task and do not go further\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;66;03m# we can add support for exploring subflows for tasks in the future.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misasync, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, parameters)\n\u001b[1;32m-> 1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menter_flow_run_engine_from_flow_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\engine.py:297\u001b[0m, in \u001b[0;36menter_flow_run_engine_from_flow_call\u001b[1;34m(flow, parameters, wait_for, return_type)\u001b[0m\n\u001b[0;32m    290\u001b[0m     retval \u001b[38;5;241m=\u001b[39m from_async\u001b[38;5;241m.\u001b[39mwait_for_call_in_loop_thread(\n\u001b[0;32m    291\u001b[0m         begin_run,\n\u001b[0;32m    292\u001b[0m         done_callbacks\u001b[38;5;241m=\u001b[39mdone_callbacks,\n\u001b[0;32m    293\u001b[0m         contexts\u001b[38;5;241m=\u001b[39mcontexts,\n\u001b[0;32m    294\u001b[0m     )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_sync\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_call_in_loop_thread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbegin_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdone_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdone_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\api.py:243\u001b[0m, in \u001b[0;36mfrom_sync.wait_for_call_in_loop_thread\u001b[1;34m(_from_sync__call, timeout, done_callbacks, contexts)\u001b[0m\n\u001b[0;32m    241\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(context)\n\u001b[0;32m    242\u001b[0m waiter\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py:317\u001b[0m, in \u001b[0;36mCall.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    Wait for the result of the call.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    Not safe for use from asynchronous contexts.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py:178\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Raise Prefect cancelled error instead of\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# `concurrent.futures._base.CancelledError`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py:388\u001b[0m, in \u001b[0;36mCall._run_async\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39menforce_async_deadline() \u001b[38;5;28;01mas\u001b[39;00m cancel_scope:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 388\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;66;03m# Forget this call's arguments in order to free up any memory\u001b[39;00m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;66;03m# that may be referenced by them; after a call has happened,\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;66;03m# there's no need to keep a reference to them\u001b[39;00m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\client\\utilities.py:44\u001b[0m, in \u001b[0;36minject_client.<locals>.with_injected_client\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     client \u001b[38;5;241m=\u001b[39m task_run_context\u001b[38;5;241m.\u001b[39mclient\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# A new client is needed\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     client_context \u001b[38;5;241m=\u001b[39m \u001b[43mget_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Removes existing client to allow it to be set by setdefault below\u001b[39;00m\n\u001b[0;32m     47\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\client\\orchestration.py:164\u001b[0m, in \u001b[0;36mget_client\u001b[1;34m(httpx_settings)\u001b[0m\n\u001b[0;32m    160\u001b[0m api \u001b[38;5;241m=\u001b[39m PREFECT_API_URL\u001b[38;5;241m.\u001b[39mvalue()\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# create an ephemeral API if none was provided\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_app\n\u001b[0;32m    166\u001b[0m     api \u001b[38;5;241m=\u001b[39m create_app(ctx\u001b[38;5;241m.\u001b[39msettings, ephemeral\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PrefectClient(\n\u001b[0;32m    169\u001b[0m     api,\n\u001b[0;32m    170\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mPREFECT_API_KEY\u001b[38;5;241m.\u001b[39mvalue(),\n\u001b[0;32m    171\u001b[0m     httpx_settings\u001b[38;5;241m=\u001b[39mhttpx_settings,\n\u001b[0;32m    172\u001b[0m )\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, orchestration, schemas, services\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\models\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     agents,\n\u001b[0;32m      3\u001b[0m     artifacts,\n\u001b[0;32m      4\u001b[0m     block_documents,\n\u001b[0;32m      5\u001b[0m     block_registration,\n\u001b[0;32m      6\u001b[0m     block_schemas,\n\u001b[0;32m      7\u001b[0m     block_types,\n\u001b[0;32m      8\u001b[0m     concurrency_limits,\n\u001b[0;32m      9\u001b[0m     concurrency_limits_v2,\n\u001b[0;32m     10\u001b[0m     configuration,\n\u001b[0;32m     11\u001b[0m     deployments,\n\u001b[0;32m     12\u001b[0m     flow_run_input,\n\u001b[0;32m     13\u001b[0m     flow_run_notification_policies,\n\u001b[0;32m     14\u001b[0m     flow_run_states,\n\u001b[0;32m     15\u001b[0m     flow_runs,\n\u001b[0;32m     16\u001b[0m     flows,\n\u001b[0;32m     17\u001b[0m     logs,\n\u001b[0;32m     18\u001b[0m     saved_searches,\n\u001b[0;32m     19\u001b[0m     task_run_states,\n\u001b[0;32m     20\u001b[0m     task_runs,\n\u001b[0;32m     21\u001b[0m     variables,\n\u001b[0;32m     22\u001b[0m     work_queues,\n\u001b[0;32m     23\u001b[0m     workers,\n\u001b[0;32m     24\u001b[0m )\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\models\\agents.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m delete, select\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mschemas\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inject_db\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrefectDBInterface\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@inject_db\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_agent\u001b[39m(\n\u001b[0;32m     19\u001b[0m     session: sa\u001b[38;5;241m.\u001b[39morm\u001b[38;5;241m.\u001b[39mSession,\n\u001b[0;32m     20\u001b[0m     agent: schemas\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mAgent,\n\u001b[0;32m     21\u001b[0m     db: PrefectDBInterface,\n\u001b[0;32m     22\u001b[0m ):\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\database\\dependencies.py:14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Type\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigurations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     AioSqliteConfiguration,\n\u001b[0;32m     11\u001b[0m     AsyncPostgresConfiguration,\n\u001b[0;32m     12\u001b[0m     BaseDatabaseConfiguration,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrefectDBInterface\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morm_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     AioSqliteORMConfiguration,\n\u001b[0;32m     17\u001b[0m     AsyncPostgresORMConfiguration,\n\u001b[0;32m     18\u001b[0m     BaseORMConfiguration,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     AioSqliteQueryComponents,\n\u001b[0;32m     22\u001b[0m     AsyncPostgresQueryComponents,\n\u001b[0;32m     23\u001b[0m     BaseQueryComponents,\n\u001b[0;32m     24\u001b[0m )\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\database\\interface.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malembic_commands\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alembic_downgrade, alembic_upgrade\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigurations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDatabaseConfiguration\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morm_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseORMConfiguration\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseQueryComponents\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dialect\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\database\\orm_models.py:31\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mschemas\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     JSON,\n\u001b[0;32m     22\u001b[0m     UUID,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     now,\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencryption\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decrypt_fernet, encrypt_fernet\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnames\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_slug\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mORMBase\u001b[39;00m:\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\utilities\\encryption.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfernet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fernet\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m schemas\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_fernet_encryption\u001b[39m(session):\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\cryptography\\fernet.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidSignature\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashes, padding\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mciphers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cipher, algorithms, modes\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\cryptography\\exceptions.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rust\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m rust_exceptions\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mTYPE_CHECKING:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rust\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m openssl \u001b[38;5;28;01mas\u001b[39;00m rust_openssl\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _rust: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "@flow(name=\"Orchestrate pipeline\", retries=3)\n",
    "def run_pipeline():\n",
    "  raw_df = extract_all_tickers()\n",
    "  transformed_df = transform_data(raw_df)\n",
    "  load_duckdb(transformed_df, \"finance-DWH.db\", \"dim_companies\")\n",
    "\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction yfinance\n",
    "After successfully extracting data from the polygon finance API, we are interested in the column of tickers from the dataframe. This ticker list will then be used to extract historical data information for the maximum period of companies.\n",
    "\n",
    "NOTE : Polygon finance limits the free tier to only 2 years of historical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@task(name=\"extract-historical-data-yfinance\", log_prints=True, retries=3)\n",
    "def extract_yfinance(polygon_df):\n",
    "\n",
    "  # Extract the ticker column from your polygon finance data\n",
    "  tickers_arr = polygon_df.ticker.to_list()\n",
    "\n",
    "  # set ticker symbols for yahoo finance\n",
    "  tickers = yf.Tickers(tickers_arr)\n",
    "\n",
    "  # extract historical information of the tickers for the maximum period at intervals of 1d\n",
    "  tickers_hist = tickers.history(period=\"max\", interval=\"1d\")\n",
    "\n",
    "  # Load the data in a dataframe\n",
    "  hist_df = pd.DataFrame(tickers_hist)\n",
    "\n",
    "  return hist_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(name=\"transform-yfinance\", log_prints=True, retries=3)\n",
    "def transform(yfinance_df, polygon_df=None):\n",
    "\n",
    "  # transpose the dataframe\n",
    "  transformed_df = yfinance_df.stack(level=1).rename_axis(['Date', 'ticker']).reset_index(level=1)\n",
    "\n",
    "  # drop the Adj Close and Capital Gains\n",
    "  transformed_df =  transformed_df.loc[:, ['ticker', 'Open','Close','High','Low','Stock Splits','Volume']]\n",
    "\n",
    "  # add a date column in transformed_df\n",
    "  transformed_df[\"date\"] = pd.to_datetime(transformed_df.index)\n",
    "\n",
    "  # merge the polygon finance dataframe and the yfinance\n",
    "  merged_df = pd.merge(left=transformed_df, right=polygon_df, on=\"ticker\")\n",
    "\n",
    "  # drop the unnecessary columns in merged dataframes\n",
    "  #merged_clean_df = merged_df.drop(columns=['locale', 'primary_exchange', 'type', 'active',\n",
    "       #'currency_name', 'cik', 'composite_figi', 'share_class_figi',\n",
    "       #'last_updated_utc'], inplace=True)\n",
    "\n",
    "  merged_clean_df =  merged_df.loc[:, ['date','ticker','name','market', 'Open','Close','High','Low','Volume','Stock Splits']]\n",
    "\n",
    "  # set the date as the index\n",
    "  merged_clean_df.set_index('date', inplace=True)\n",
    "\n",
    "  return merged_clean_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(name=\"load facts\", log_prints=True, retries=3)\n",
    "def load_duckdb(dataframe, db_name, table_name):\n",
    "  \"\"\"Load the cleaned dataframe into a duckdb database\n",
    "\n",
    "  Parameters:\n",
    "    dataframe : input dataframe to be loaded to database\n",
    "    db_name : database to load data in\n",
    "    table_name : table in database where data is loaded\n",
    "  \"\"\"\n",
    "  # connect to duckdb\n",
    "  con = duckdb.connect(db_name)\n",
    "\n",
    "  # write the dataframe to duckdb\n",
    "  dataframe.to_sql(name=table_name, con=con, if_exists=\"replace\", index=\"True\")\n",
    "  print(f\"Data succesfully written to {db_name}\")\n",
    "\n",
    "\n",
    "  # read the data from sql\n",
    "  loaded_df = pd.read_sql(f\"SELECT * FROM {table_name}\", con=con)\n",
    "  print(loaded_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow(name=\"run-facts-pipeline\", log_prints=True, retries=3)\n",
    "def run_pipeline():\n",
    "\n",
    "  polygon_data = extract_all_tickers()\n",
    "  yfinance_data = extract_yfinance(polygon_data)\n",
    "\n",
    "  transformed_data = transform(yfinance_data, polygon_data)\n",
    "\n",
    "  load_duckdb(transformed_data, \"historical-DWH.db\", \"fact_table\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _rust: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m   \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m   run_pipeline\u001b[38;5;241m.\u001b[39mserve(\n\u001b[0;32m      4\u001b[0m       name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistorical-facts-pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m       cron \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m* * * * *\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m   )\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\flows.py:1224\u001b[0m, in \u001b[0;36mFlow.__call__\u001b[1;34m(self, return_state, wait_for, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_viz_tracker:\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# this is a subflow, for now return a single task and do not go further\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;66;03m# we can add support for exploring subflows for tasks in the future.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misasync, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, parameters)\n\u001b[1;32m-> 1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menter_flow_run_engine_from_flow_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\engine.py:297\u001b[0m, in \u001b[0;36menter_flow_run_engine_from_flow_call\u001b[1;34m(flow, parameters, wait_for, return_type)\u001b[0m\n\u001b[0;32m    290\u001b[0m     retval \u001b[38;5;241m=\u001b[39m from_async\u001b[38;5;241m.\u001b[39mwait_for_call_in_loop_thread(\n\u001b[0;32m    291\u001b[0m         begin_run,\n\u001b[0;32m    292\u001b[0m         done_callbacks\u001b[38;5;241m=\u001b[39mdone_callbacks,\n\u001b[0;32m    293\u001b[0m         contexts\u001b[38;5;241m=\u001b[39mcontexts,\n\u001b[0;32m    294\u001b[0m     )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_sync\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_call_in_loop_thread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbegin_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdone_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdone_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\api.py:243\u001b[0m, in \u001b[0;36mfrom_sync.wait_for_call_in_loop_thread\u001b[1;34m(_from_sync__call, timeout, done_callbacks, contexts)\u001b[0m\n\u001b[0;32m    241\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(context)\n\u001b[0;32m    242\u001b[0m waiter\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py:317\u001b[0m, in \u001b[0;36mCall.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    Wait for the result of the call.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    Not safe for use from asynchronous contexts.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py:178\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Raise Prefect cancelled error instead of\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# `concurrent.futures._base.CancelledError`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py:388\u001b[0m, in \u001b[0;36mCall._run_async\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39menforce_async_deadline() \u001b[38;5;28;01mas\u001b[39;00m cancel_scope:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 388\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;66;03m# Forget this call's arguments in order to free up any memory\u001b[39;00m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;66;03m# that may be referenced by them; after a call has happened,\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;66;03m# there's no need to keep a reference to them\u001b[39;00m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\client\\utilities.py:44\u001b[0m, in \u001b[0;36minject_client.<locals>.with_injected_client\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     client \u001b[38;5;241m=\u001b[39m task_run_context\u001b[38;5;241m.\u001b[39mclient\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# A new client is needed\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     client_context \u001b[38;5;241m=\u001b[39m \u001b[43mget_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Removes existing client to allow it to be set by setdefault below\u001b[39;00m\n\u001b[0;32m     47\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\client\\orchestration.py:164\u001b[0m, in \u001b[0;36mget_client\u001b[1;34m(httpx_settings)\u001b[0m\n\u001b[0;32m    160\u001b[0m api \u001b[38;5;241m=\u001b[39m PREFECT_API_URL\u001b[38;5;241m.\u001b[39mvalue()\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# create an ephemeral API if none was provided\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_app\n\u001b[0;32m    166\u001b[0m     api \u001b[38;5;241m=\u001b[39m create_app(ctx\u001b[38;5;241m.\u001b[39msettings, ephemeral\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PrefectClient(\n\u001b[0;32m    169\u001b[0m     api,\n\u001b[0;32m    170\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mPREFECT_API_KEY\u001b[38;5;241m.\u001b[39mvalue(),\n\u001b[0;32m    171\u001b[0m     httpx_settings\u001b[38;5;241m=\u001b[39mhttpx_settings,\n\u001b[0;32m    172\u001b[0m )\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, orchestration, schemas, services\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\models\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     agents,\n\u001b[0;32m      3\u001b[0m     artifacts,\n\u001b[0;32m      4\u001b[0m     block_documents,\n\u001b[0;32m      5\u001b[0m     block_registration,\n\u001b[0;32m      6\u001b[0m     block_schemas,\n\u001b[0;32m      7\u001b[0m     block_types,\n\u001b[0;32m      8\u001b[0m     concurrency_limits,\n\u001b[0;32m      9\u001b[0m     concurrency_limits_v2,\n\u001b[0;32m     10\u001b[0m     configuration,\n\u001b[0;32m     11\u001b[0m     deployments,\n\u001b[0;32m     12\u001b[0m     flow_run_input,\n\u001b[0;32m     13\u001b[0m     flow_run_notification_policies,\n\u001b[0;32m     14\u001b[0m     flow_run_states,\n\u001b[0;32m     15\u001b[0m     flow_runs,\n\u001b[0;32m     16\u001b[0m     flows,\n\u001b[0;32m     17\u001b[0m     logs,\n\u001b[0;32m     18\u001b[0m     saved_searches,\n\u001b[0;32m     19\u001b[0m     task_run_states,\n\u001b[0;32m     20\u001b[0m     task_runs,\n\u001b[0;32m     21\u001b[0m     variables,\n\u001b[0;32m     22\u001b[0m     work_queues,\n\u001b[0;32m     23\u001b[0m     workers,\n\u001b[0;32m     24\u001b[0m )\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\models\\agents.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m delete, select\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mschemas\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inject_db\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrefectDBInterface\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@inject_db\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_agent\u001b[39m(\n\u001b[0;32m     19\u001b[0m     session: sa\u001b[38;5;241m.\u001b[39morm\u001b[38;5;241m.\u001b[39mSession,\n\u001b[0;32m     20\u001b[0m     agent: schemas\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mAgent,\n\u001b[0;32m     21\u001b[0m     db: PrefectDBInterface,\n\u001b[0;32m     22\u001b[0m ):\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\database\\dependencies.py:14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Type\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigurations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     AioSqliteConfiguration,\n\u001b[0;32m     11\u001b[0m     AsyncPostgresConfiguration,\n\u001b[0;32m     12\u001b[0m     BaseDatabaseConfiguration,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrefectDBInterface\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morm_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     AioSqliteORMConfiguration,\n\u001b[0;32m     17\u001b[0m     AsyncPostgresORMConfiguration,\n\u001b[0;32m     18\u001b[0m     BaseORMConfiguration,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     AioSqliteQueryComponents,\n\u001b[0;32m     22\u001b[0m     AsyncPostgresQueryComponents,\n\u001b[0;32m     23\u001b[0m     BaseQueryComponents,\n\u001b[0;32m     24\u001b[0m )\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\database\\interface.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malembic_commands\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alembic_downgrade, alembic_upgrade\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigurations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDatabaseConfiguration\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morm_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseORMConfiguration\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseQueryComponents\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dialect\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\database\\orm_models.py:31\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mschemas\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     JSON,\n\u001b[0;32m     22\u001b[0m     UUID,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     now,\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencryption\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decrypt_fernet, encrypt_fernet\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnames\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_slug\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mORMBase\u001b[39;00m:\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\prefect\\server\\utilities\\encryption.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfernet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fernet\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprefect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m schemas\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_fernet_encryption\u001b[39m(session):\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\cryptography\\fernet.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidSignature\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashes, padding\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mciphers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cipher, algorithms, modes\n",
      "File \u001b[1;32me:\\data_engineering_projects\\phoenix_analytics_de_workshop\\phx-analytics-de-capstone\\venv\\lib\\site-packages\\cryptography\\exceptions.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rust\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m rust_exceptions\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mTYPE_CHECKING:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rust\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m openssl \u001b[38;5;28;01mas\u001b[39;00m rust_openssl\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _rust: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  run_pipeline()\n",
    "  run_pipeline.serve(\n",
    "      name = \"historical-facts-pipeline\",\n",
    "      cron = \"* * * * *\",\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
